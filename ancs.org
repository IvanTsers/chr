#+begin_export latex
\section{Implementation}
Package \ty{ancs} has hooks for imports, data structures and methods.
#+end_export
#+begin_src go <<ancs.go>>=
  package ancs
  import (
	  //<<Imports>>
  )
  //<<Data structures>>
  //<<Methods>>
  //<<Functions>>
#+end_src
#+begin_export latex
\subsection{Data structure \ty{Seg}}
We declare a data type \ty{Seg} for storing segments of the forward
strand of the subject.

!Data type \ty{Seg} contains a zero-based start and length of a
!segment.
#+end_export
#+begin_src go <<Data structures>>=
  type Seg struct {
	  s int
	  l int
  }
#+end_src
#+begin_export latex
\subsection{Methods}
\subsubsection{\ty{End}}
!Method \ty{End()} returns an inclusive coordinate of the end of a
!segment.

Thus, the package operates with zero-based end-inclusive coordinates.
#+end_export
#+begin_src go <<Methods>>=
  func (seg *Seg) End() int {
	  return seg.s + seg.l
  }
#+end_src
#+begin_export latex
\subsubsection{Method \ty{NewSeg}}
!Constructor method \ty{NewSeg()} returns a segment of specified start
!and length.
#+end_export
#+begin_src go <<Methods>>=
  func NewSeg(x, y int) Seg {
	  return Seg{s:x, l:y}
  }
#+end_src
#+begin_export latex
\subsection{Functions}
The \ty{ancs} package contains a number of functions.
#+end_export
#+begin_src go <<Functions>>=
  //<<SortByStart>>
  //<<FindHomologies>>
  //<<ReduceOverlaps>>
  //<<TotalSegLen>>
  //<<PrintSegSiteRanges>>
  //<<SegToFasta>>
#+end_src
#+begin_export latex
\subsubsection{\ty{SortByStart}}
!\ty{SortByStart} accepts a slice of segments \ty{s} and sorts the
!segments by their start positions in ascending order.
#+end_export
#+begin_src go <<SortByStart>>=
  func SortByStart(s []Seg) []Seg {
          sort.Slice(s, func(i, j int) bool {
                  return s[i].s < s[j].s
          })
          return s
  }
#+end_src
#+begin_export latex
We import \ty{sort}.
#+end_export
#+begin_src go <<Imports>>=
  "sort"
#+end_src
#+begin_export latex
\subsubsection{\ty{FindHomologies}}
!The function \ty{FindHomologies} accepts query and subject sequences,
!an enhanced suffix array of the subject, and the minimum anchor
!length \ty{a}. The function returns a slice of segments (homologous
!regions, or homologies) and a bool map of segregation sites found
!within the homologies. If no homologies have been found, an empty
!slice of segments and empty map of segregation sites are returned.

We initialize variables to operate with in the search of homologies,
conduct the search, and return its results.
#+end_export
#+begin_src go <<FindHomologies>>=
  func FindHomologies(
	  query *fasta.Sequence,
	  subject *fasta.Sequence,
	  e *esa.Esa,
	  a int) ([]Seg, map[int]bool) {
	  //<<Initialize search>>
	  //<<Anchor search>>
	  //<<Return the output>>
  }
#+end_src
#+begin_export latex
We import \ty{fasta} and \ty{esa}.
#+end_export
#+begin_src go <<Imports>>=
  "github.com/ivantsers/fasta"
  "github.com/evolbioinf/esa"
#+end_src
#+begin_export latex
We declare variables to operate with during the search. These are:
\begin{itemize}
  \itemsep0em
  \item current and previous positions in the query;
  \item current match: its length and start in the subject;
  \item previous match: its length, start and end the subject;
  \item current segment;
  \item a slice of segments to store the output in;
  \item a map to store positions of segregation sites (mismatches);
  \item an indicator of the right anchor;
  \item full length of the subject;
  \item length of a \ty{single strand} of the subject;
  \item length of the query.
\end{itemize}
#+end_export
#+begin_src go <<Initialize search>>=
  var qc, qp int
  var currLen, currStartS int
  var prevLen, prevStartS, prevEndS int
  var seg Seg
  var h []Seg
  n := make(map[int]bool)
  rightAnchor := false
  subjectLen := subject.Length()
  subjectStrandLen := subjectLen/2
  queryLen := query.Length()
#+end_src
#+begin_export latex
We perform anchor search for each prefix in our query. We get a prefix
that starts at the current position and ends at the last byte of the
query. Then we search for an anchor. There are two scenarios: 1) there
is a match that starts right after the last mismatch, 2) there is a
'remote' match somewhere else. There are two functions to be
written.

In the first case, we try to find the longest common prefix at the
given positions in the query and the subject using the function
\ty{anchorLcp}. In the second case, we turn to the ESA and look for a
matching suffix using the function \ty{anchorEsa}. Both functions
advance in the subject and update \ty{currStartS} and \ty{currLen},
both functions return \ty{true} if a legitimate match is found.

We put both functions into a short-circuit evaluation, that is,
\ty{anchorEsa} is called only if \ty{anchorLcp} has returned
\ty{false}. If a match is found, we proceed with calculating the end
positions of the previous match in the query and the subject. Then we
analyze the current match and decide, whether the current segment can
be extended with it. If so, we extend the current segment. If it
cannot be extended and the right anchor is found, we open a new
segment and save the current one in \ty{h}. After these operations, we
remember the current match and jump in the query by at least one
nucleotide, which is most likely to be a mutation. Then we proceed
with the next prefix.
#+end_export
#+begin_src go <<Anchor search>>=
  for qc < queryLen {
	  queryPrefix := query.Data()[qc:queryLen]
	  if <<LCP anchor>> || <<ESA anchor>> {
	  prevEndQ := qp + prevLen
	  prevEndS = prevStartS + prevLen
	  //<<Analyze the match>>
	  if segCanBeExtended {
		  //<<Extend the current segment>>
	  } else {
		  if rightAnchor || prevLen / 2 >= a {
			  //<<Close the current segment>>
		  }
		  //<<Open a new segment>>
	  }
	  //<<Remember the current match>>
  }
  qc = qc + currLen + 1
  }
  //Close the last segment if open:
  if rightAnchor || prevLen / 2 >= a {
  if seg.s > subjectStrandLen {
	  seg.s = subjectLen + 1 - seg.s - seg.l
  }
  h = append(h, seg)
  }
#+end_src
#+begin_export latex
We call \ty{lcpAnchor} with numerous arguments. The funtion itself is
yet to be written.
#+end_export
#+begin_src go <<LCP anchor>>=
  lcpAnchor(&currStartS, &currLen,
	  prevStartS, prevLen,
	  subjectLen, queryLen, qc, qp,
	  a, queryPrefix, subject)
#+end_src
#+begin_export latex
!The function \ty{lcpAnchor} accepts the following inputs: 1) pointer
!to the current match length; 2) start of the current match in the
!subject; 3) a map of segregation sites; 4) the minimum anchor length;
!5) the current query prefix; 6) a pointer to the subject. The
!function returns a boolean. Regardless of the significance of the
!match, the function updates the start and the length of the current
!match.

First, the function calculates the gap between the current and
previous positions in the query, and determines a position in the
subject to attempt matching the longest common prefix (LCP). If this
position is beyond the end of the subject or if the gap is larger than
the minimum anchor length (meaning it's not random), the function
returns \ty{false}. Otherwise, it updates the position in the subject
and finds the LCP length at this position. The length of the current
match is then updated with the found length. If this length meets the
minimum anchor length requirement, the match is considered
significant, and the function returns \ty{true}.
#+end_export
#+begin_src go <<Functions>>=
  func lcpAnchor(currStartS, currLen *int,
	  prevStartS, prevLen int,
	  subjectLen, queryLen int,
	  qc, qp int,
	  a int,
	  queryPrefix []byte,
	  subject *fasta.Sequence) bool {
	  advance := qc - qp
	  gap := advance - prevLen
	  tryS := prevStartS + advance
	  if tryS >= subjectLen || gap > a {                          
		  return false
	  }
	  *currStartS = tryS
	  newCurrLen := lcp(queryLen,
		  queryPrefix, subject.Data()[tryS:])
	  *currLen = newCurrLen
	  return newCurrLen >= a
  }
#+end_src
#+begin_export latex
The function \ty{lcp} returns length of the longest common prefix
of two slices of bytes.
#+end_export
#+begin_src go <<Functions>>=
  func lcp(max int, a, b []byte) int {
      count := 0
      for i := 0; i < max; i++ {
	  if i >= len(a) || i >= len(b) || a[i] != b[i] {
	      break
	  }
	  count++
      }
      return count
  }
#+end_src
#+begin_src go <<ESA anchor>>=
  esaAnchor(&currStartS, &currLen, a, queryPrefix, e)
#+end_src
#+begin_export latex
!The function \ty{anchorEsa()} accepts: 1) a pointer to the current
!match length; 2) start of the match the subject; 3) a map of
!segregation sites; 4) the minimum anchor length; 5) the current query
!prefix; 6) a pointer to the subject ESA. The function returns a
!boolean. Regardless of the significance of the match, the function
!updates the start and the length of the current match.

A match is considered significant if it is unique and not shorter than
the minimum anchor length. A match is unique if it starts and ends at
the same position in an ESA. In terms of a suffix tree, a unique match
ends on a leaf.
#+end_export
#+begin_src go <<Functions>>=
  func esaAnchor(
	  currStartS, currLen *int,
	  a int,
	  queryPrefix []byte,
	  e *esa.Esa) bool {
	  mc := e.MatchPref(queryPrefix)
	  newStartS := e.Sa[mc.I]
	  newCurrLen := mc.L
	  *currStartS = newStartS
	  *currLen = newCurrLen
	  lu := (mc.J == mc.I) && (newCurrLen >= a)
	  return lu
  }
#+end_src
#+end_export
#+begin_export latex
We analyze if the match:
\begin{itemize}
  \itemsep0em
  \item starts in the subject after the previous match;
  \item is equidistant with the previous match in the subject and
    query;
  \item is located on the same strand in the subject as the previous
    match.
\end{itemize}
If these criteria are met, we qualify the current segment as
extendible.
#+end_export
#+begin_src go <<Analyze the match>>=
  afterPrev := currStartS > prevEndS

  areEquidist := qc - prevEndQ == currStartS - prevEndS

  onSameStrand := (currStartS < subjectStrandLen) ==
		  (prevStartS < subjectStrandLen)

  segCanBeExtended := afterPrev &&
		      areEquidist &&
		      onSameStrand
#+end_src
#+begin_export latex
We extend the segment to the end of the new anchor and add positions
between the end of the last left anchor and the start right anchor to
the map of mismatches as keys. We also remember that we have just
found a new right anchor.
#+end_export
#+begin_src go <<Extend the current segment>>=
  prevSegEnd := seg.End()
  gap := qc - prevEndQ
  seg.l = seg.l + gap + currLen
  a := subject.Data()[prevSegEnd:prevSegEnd + gap]
  b := query.Data()[prevEndQ:prevEndQ + gap]

  for i := 0; i < gap; i++ {
	  if a[i] != b[i] {
		  n[prevSegEnd + i] = true
	  }
  }
  rightAnchor = true
#+end_src
#+begin_export latex
To close the current segment is to project it onto the forward strand
(if necessary) and append it to the slice of homologies..
#+end_export
#+begin_src go <<Close the current segment>>=
  if seg.s > subjectStrandLen {
	  seg.s = subjectLen + 1 - seg.s - seg.l
  }
  h = append(h, seg)
#+end_src
#+begin_export latex
To open a segment is to declare its start and length, and forget that
the right anchor was found.
#+end_export
#+begin_src go <<Open a new segment>>=
  seg.s = currStartS
  seg.l = currLen
  rightAnchor = false
#+end_src
#+begin_export latex
We update previous position in the query and the previous match.
#+end_export
#+begin_src go <<Remember the current match>>=
  qp = qc
  prevLen = currLen
  prevStartS = currStartS
#+end_src
#+begin_export latex
We return the output of \ty{FindHomologies()} if the slice of
homologies is not empty. If it is empty, we return an empty slice of
segments and empty \ty{n}.
#+end_export
#+begin_src go <<Return the output>>=
  return h, n
#+end_src
#+begin_export latex
\subsubsection{\ty{ReduceOverlaps}}
!\ty{ReduceOverlaps()} accepts a sorted slice of segments
(homologies) and returns a slice of segments, which contains the
longest chain of non-overlapping homologies.

If \texttt{h} contains less than two elements, we return
early. Otherwise, we reduce overlapping stacks of homologies to the
longest chain of co-linear non-overlapping homologies using the
algorithm for two-dimensional fragment chaining. We start with
initializing variables, then we calculate chain scores, find links of
the longest chain through backtracking, and return the chain.
#+end_export
#+begin_src go <<ReduceOverlaps>>=
  func ReduceOverlaps(h []Seg) []Seg {
	  hlen := len(h)
	  if hlen < 2 {
		  return h
	  }
	  //<<Initialize chaining>>
	  //<<Calculate chain score>>
	  //<<Backtrack the chain>>
	  //<<Return the chain>>
  }
#+end_src
#+begin_export latex
We declare variables describing the chain. For each homology \ty{i} we
initialize:
\begin{itemize}
  \itemsep0em
  \item \ty{predecessor}---the previous homology in the longest chain
    ending before \ty{i});
  \item \ty{score}---the length of the longest chain ending at
    \ty{i}. The initial score of the chain is the first
    homology's length;
  \item \ty{visited}---whether \ty{i} was visited in backtracking of
    chain links.
\end{itemize}
We also initialize the first elements for \ty{score} and
\ty{predecessor}.
#+end_export
#+begin_src go <<Initialize chaining>>=
  predecessor := make([]int, hlen)
  score := make([]int, hlen)
  visited := make([]bool, hlen)
  score[0] = h[0].l
  predecessor[0] = -1
#+end_src
#+begin_export latex
We calculate the chain score to maximize the number of non-overlapping
segments in \ty{h}. Starting from the second homology \ty{h[1]}, we
traverse each homology \ty{h[i]} in the sequence. For each \ty{h[i]},
we find the preceding homology \ty{h[k]} that can form the longest
chain ending before \ty{h[i]} starts, ensuring no overlap.
#+end_export
#+begin_src go <<Calculate chain score>>=
  for i := 1; i < hlen; i++ {
	  maxScore := 0
	  maxIndex := -1
	  for k := 0; k < i; k++ {
		  if h[k].End() < h[i].s {
			  if score[k] > maxScore {
				  maxScore = score[k]
				  maxIndex = k
			  }
		  }
	  }
	  predecessor[i] = maxIndex
	  if maxIndex != -1 {
	      score[i] = h[i].l + score[maxIndex]
	  } else {
	      score[i] = h[i].l
	  }
  }
  // Debug messages. Will be removed in the future
  //fmt.Println("***Homologies:")
  //for _, el := range(h) {
  //	fmt.Printf("***(%d, %d)\n", el.s, el.End())
  //}
  //fmt.Println("***Scores:", score)
#+end_src
#+begin_export latex
After calculating the scores for all homologies, we need to find
\ty{s}, which is the index of the homology in \texttt{h} with the
highest score. This homology is the final link in the chain we're
looking for, and its score is the total score of the chain. To find
\ty{s}, we'll use the \ty{argmaxMapInt()} function, which still needs
to be written. Once we identify \ty{s}, we backtrack through the
predecessor links to trace the entire chain and mark the homologies as
visited.
#+end_export
#+begin_src go <<Backtrack the chain>>=
  s := argmax(score)
  for s != -1 {
	  visited[s] = true
	  s = predecessor[s]
  }
#+end_src
#+begin_export latex
The function \ty{argmax()} returns the index of the maximum value in
the input slice of integers.
#+end_export
#+begin_src go <<Functions>>=
  func argmax(x []int) int {
      maxIdx := 0
      for i := 1; i < len(x); i++ {
	  if x[i] > x[maxIdx] {
	      maxIdx = i
	  }
      }
      return maxIdx
  }
#+end_src
#+begin_export latex
We extract only visited elements of \ty{h} and return the reduced
slice.
#+end_export
#+begin_src go <<Return the chain>>=
  var hred []Seg
  for i := 0; i < len(h); i++ {
	  if visited[i] {
		  hred = append(hred, h[i])
	  }
  }
  return hred
#+end_src
#+begin_export latex
!\ty(TotalSegLen()) accepts a slice of segments and returns their
!total length.
#+end_export
#+begin_src go <<TotalSegLen>>=
  func TotalSegLen(segments []Seg) int {
	  sumlen := 0
	  for _, s := range(segments) {
		  sumlen += s.l
	  }
	  return sumlen
  }
#+end_src
#+begin_export latex
\subsubsection{\ty{PrintSegSiteRanges}}
!\ty{PrintSegSiteRanges()} accepts a bool map of Ns (segregation
!sites), a slice of segments, and a pointer to an output file, and
!prints segregation site coordinate ranges.

Segregation sites make sense only in the context of homologous
regions, so we print only sites found within a homologous segment.
#+end_export
#+begin_src go <<PrintSegSiteRanges>>=
  func PrintSegsiteRanges(n map[int]bool,
	  h []Seg, file *os.File) {
	  if len(n) == 0 {
		  fmt.Fprintf(file, "No segregation sites found\n")
	  } else {
		  for _, seg := range h {
			  //<<Print segsites found within a homology>>
		  }
	  }
  }
#+end_src
#+begin_export latex
We import \ty{os} and \ty{fmt}.
#+end_export
#+begin_src go <<Imports>>=
  "os"
  "fmt"
#+end_src
#+begin_export latex
We extract the relevant positions and store them in the slice
\ty{k}. Then we scan the slice for ranges.
#+end_export
#+begin_src go <<Print segsites found within a homology>>=
  //<<Extract relevant positions>>
  for i := 1; i < len(k) - 1; i++ {
	  //<<Scan for segsite ranges>>
  }
  fmt.Fprintf(file, "\n")
#+end_src
#+begin_export latex
We traverse \ty{n} from the start to the end of the current homology,
find existing keys, convert them to 1-based coordinates \textit{on the
  given homology}, and save the coordinate in a slice. We flank the
slice of those keys with \ty{-1}.
#+end_export
#+begin_src go <<Extract relevant positions>>=
  k := []int{-1}
  for i := seg.s; i < seg.End(); i++ {
	  if n[i] {
		  k = append(k, i - seg.s + 1)
	  }
  }
  k = append(k, -1)
#+end_src
#+begin_export latex
We check if \ty{k[i]} is surrounded by a preceding and consecutive
numbers. We format the output depending on the combination of possible
outcomes. If \ty{k[i]} is surrounded by such numbers, we proceed to
\ty{k[i]}. If the consecutive value exists, we open square
brackets. Should the previous, but not the next value exist, we close
brackets. If there are no next and previous values, we print \ty{k[i]}.
#+end_export
#+begin_src go <<Scan for segsite ranges>>=
  prev := k[i] == k[i-1]+1
  next := k[i] == k[i+1]-1
  if prev && next {
	  continue
  }
  if next {
	  fmt.Fprintf(file, "[%d", k[i]+1)
  } else if prev {
	  fmt.Fprintf(file, ":%d] ", k[i]+1)
  } else {
	  fmt.Fprintf(file, "%d ", k[i]+1)
  }
#+end_src
#+begin_export latex
\subsubsection{\ty{SegToFasta}}
!\ty{SegToFasta()} converts a slice of segments into actual fasta
!sequences. It accepts a slice of segments, a pointer to the
!corresponding ESA, a map of Ns, and a \ty{bool} toggle for printing
!\ty{Ns}. It returns a slice of pointers to fasta entries (type
!\ty{fasta.Sequence}).
#+end_export
#+begin_src go <<SegToFasta>>=
  func SegToFasta(segments []Seg,
	  e *esa.Esa,
	  n map[int]bool,
	  printNs bool) []*fasta.Sequence {
	  var segfasta []*fasta.Sequence
	  for i, s := range(segments) {
		  start := s.s
		  end := s.End()
		  var data []byte
		  for j := start; j < end; j++ {
			  if printNs && n[j] {
				  data = append(data, 'N')
			  } else {
				  data = append(data, e.T[j])
			  }
		  }
	  segname := fmt.Sprintf("Segment_%d (%d..%d)", i+1, start+1, end + 1)
	  converted := fasta.NewSequence(segname, data)
	  segfasta = append(segfasta, converted)		
	  }
	  return segfasta
  }
#+end_src
